{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code below, which runs `nsims` simulations and compares linear, lasso, and ridge regression, change the variable `alpha` (this is equivalent to lambda, the harshness penalty we talked about) and see how that changes the behavior of the methods. Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = 10000\n",
    "n = 10000\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(n = 10000, alpha = 1):\n",
    "    \n",
    "    # Real Variables\n",
    "    A = np.random.normal(0,1,n)\n",
    "    E = np.random.normal(0,1,n)\n",
    "    I = np.random.normal(0,1,n)\n",
    "    O = np.random.normal(0,1,n)\n",
    "    U = np.random.normal(0,1,n)\n",
    "    Y = np.random.normal(0,1,n)\n",
    "    W = np.random.normal(0,1,n)\n",
    "\n",
    "    # Unrelated Variables\n",
    "    B = np.random.normal(0,1,n)\n",
    "    C = np.random.normal(0,1,n)\n",
    "    D = np.random.normal(0,1,n)\n",
    "    G = np.random.normal(0,1,n)\n",
    "    H = np.random.normal(0,1,n)\n",
    "    J = np.random.normal(0,1,n)\n",
    "    K = np.random.normal(0,1,n)\n",
    "    L = np.random.normal(0,1,n)\n",
    "    M = np.random.normal(0,1,n)\n",
    "    N = np.random.normal(0,1,n)\n",
    "\n",
    "    # Outcome\n",
    "    X = 100 + A*8.23 + E*3.48 + I*2.97 + O*5.12 + U*7.83 + Y*12.34 + W*1.38 + np.random.normal(0,15,n)\n",
    "\n",
    "\n",
    "    # Data Frame\n",
    "    df = pd.DataFrame({\"A\": A,\"E\": E, \"I\":I,\"O\":O,\"U\":U,\n",
    "                       \"B\":B,\"C\":C,\"D\":D,\"G\":G,\"H\":H,\"J\":J,\n",
    "                       \"K\":K,\"L\":L,\"M\":M,\"N\":N,\"Y\":Y,\"W\":W,\n",
    "                       \"X\":X})\n",
    "\n",
    "    feat = [\"A\",\"B\",\"C\",\"D\",\"E\",\"G\",\"H\",\"I\",\"O\", \"U\", \"J\",\"K\",\"L\",\"M\",\"N\", \"Y\",\"W\"]\n",
    "\n",
    "    #linear\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(df[feat], df[\"X\"])\n",
    "    lr_co = lr.coef_\n",
    "\n",
    "    #lasso\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(df[feat], df[\"X\"])\n",
    "    lasso_co = lasso.coef_\n",
    "\n",
    "    #ridge\n",
    "    ridge = Ridge(alpha = (n/2)*alpha) #Ridge() in sklearn and #glmnet() from python use different objective functions\n",
    "    #changing alpha to (n/2)*alpha forces them to optimize the SAME function\n",
    "    ridge.fit(df[feat], df[\"X\"])\n",
    "    ridge_co = ridge.coef_\n",
    "\n",
    "\n",
    "    conames = feat*3\n",
    "    coefs = np.concatenate([lr_co,lasso_co,ridge_co])\n",
    "\n",
    "    model = np.repeat(np.array([\"Linear\", \"LASSO\", \"Ridge\"]), [17, 17, 17], axis=0)\n",
    "\n",
    "    df = pd.DataFrame({\"conames\": conames,\n",
    "                      \"coefs\": coefs,\n",
    "                      \"model\": model})\n",
    "\n",
    "\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = compare(n = n, alpha = alpha)\n",
    "\n",
    "for i in range(1,nsims):\n",
    "    sim = sim.append(compare(n = n, alpha = alpha), ignore_index = True)\n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the coefficents in order\n",
    "sim[\"conames\"] = pd.Categorical(sim[\"conames\"], categories=[\"A\", \"E\", \"I\", \"O\", \"U\", \"Y\", \"W\",\n",
    "                                              \"B\",\"C\",\"D\",\"G\",\"H\",\"J\",\"K\",\"L\", \"M\",\"N\"])\n",
    "\n",
    "\n",
    "# all\n",
    "(ggplot(sim, aes(x = \"conames\",\n",
    "                y = \"coefs\",\n",
    "                fill = \"model\")) +\n",
    "  geom_boxplot() + ggtitle(\"All Coefficients\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just vowels\n",
    "(ggplot(sim.loc[sim['conames'].isin([\"A\", \"E\", \"I\", \"O\", \"U\", \"Y\", \"W\"]),]\n",
    ", aes(x = \"conames\",\n",
    "      y = \"coefs\",\n",
    "      fill = \"model\")) +\n",
    "  geom_boxplot() + ggtitle(\"Real Coefficients\"))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just consonants\n",
    "\n",
    "(ggplot(sim.loc[sim['conames'].isin([\"B\",\"C\",\"D\",\"G\",\"H\",\"J\",\"K\",\"L\", \"M\",\"N\"]),],\n",
    "        aes(x = \"conames\",\n",
    "        y = \"coefs\",\n",
    "        fill = \"model\")) +\n",
    "  geom_boxplot() + ggtitle(\"Unrelated Coefficients\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
