{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "from sklearn.model_selection import KFold # k-fold cv\n",
    "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
    "from sklearn.model_selection import cross_val_score # cross validation metrics\n",
    "from sklearn.model_selection import cross_val_predict # cross validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-Means\n",
    "\n",
    "Once you've chosen random cluster centers to begin with, K-means has two main steps:\n",
    "\n",
    "1. calculate which center each data point is closest to and assign it to that cluster.\n",
    "2. use those cluster assignments to recalculate the center of each cluster.\n",
    "\n",
    "Write two functions: `howFar(centers, points)`, and `calculateCenters(points, assignments)` which do 1 and 2 respectively. See below for an example of what `centers`, `points` and `assignments` will look like. (assume data points have 2 features, and that you're using euclidean distance, but assume that centers and points could be of variable lengths). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame([(10,15), (2,3), (7,7)], columns = [\"X\", \"Y\"])\n",
    "points = pd.DataFrame([(9.09,6.93),(10.79,8.76),(9.07,2.25),\n",
    "                        (7.91,12.59),(3.22,5.61),(5.04,14.04),(13.14,1.22),(3.77,1.54)], columns = [\"X\", \"Y\"])\n",
    "\n",
    "assignments = [2, 2, 2, 0, 1, 0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 0, 1, 0, 2, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your answer\n",
    "\n",
    "def howFar(centers,points):\n",
    "    assignments = []\n",
    "    for row in range(0,points.shape[0]):\n",
    "        dists = {}\n",
    "        for center in range(0, centers.shape[0]):\n",
    "            dists[center] = np.sqrt(np.sum((points.iloc[row,] - centers.iloc[center,])**2))\n",
    "        assignment = min(dists, key=dists.get)\n",
    "        assignments.append(assignment)\n",
    "    return(assignments)\n",
    "\n",
    "howFar(centers,points) == [2, 2, 2, 0, 1, 0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.475, 13.315), (3.495, 3.575), (10.5225, 4.789999999999999)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments =  [2, 2, 2, 0, 1, 0, 2, 1]\n",
    "def calculateCenters(points, assignments):\n",
    "    new_centers = []\n",
    "    for clust in range(0, max(assignments) + 1):\n",
    "        in_clust = [i == clust for i in assignments]\n",
    "        data_in_cluster = points.loc[in_clust,]\n",
    "        X_mean = np.mean(data_in_cluster[\"X\"])\n",
    "        Y_mean = np.mean(data_in_cluster[\"Y\"])\n",
    "        new_centers.append((X_mean,Y_mean))\n",
    "    return(pd.DataFrame(new_centers))\n",
    "\n",
    "calculateCenters(points,assignments) == [(6.475, 13.315), (3.495, 3.575), (10.5225, 4.789999999999999)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN\n",
    "\n",
    "KNN calculates the distance between each data point and every other data point and finds the k nearest data points. Write a function `knn(point_to_classify, data_points, k)` that predicts/returns the class of `point_to_classify` based on `data_points` and `k`. \n",
    "\n",
    "See below for an example of what `point_to_classify` and `data_points` (each row is a data point) will look like. (Expect that `points_to_classify` could have a variable amount of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = pd.DataFrame({\"X\": [8.9,9,8.7,9.5,10.7,11.8,8.8,10.4,10,10.2,10,10.9,11.4,\n",
    "                                  9,10.3,9.7,10.4,11.3,8.6,10.2,10.9,10.9,10,8.1,10],\n",
    "                           \"Y\": [8.5,9.3,11.3,9.3,11.1,10.1,11.3,9.5,10.6,9.2,8.2,10.6,\n",
    "                                 8.4,9.8,9.4,12.2,9.4,11.7,8.5,11.4,9.9,11.6,8.8,11.9,12],\n",
    "                           \"Z\": [16.8,15.5,15,13.6,15.4,13.8,15.2,13.8,13.7,13.4,12.7,\n",
    "                                 14.4,13.9,15.1,16.2,15.4,14.5,14.6,12.6,14.6,14.1,15.7,\n",
    "                                 13.1,12.3,14.8],\n",
    "                           \"Class\": ['A','A','B','B','B','A','B','A','B','A','A','B','B',\n",
    "                                     'B','B','A','A','B','B','B','A','B','B','B','B']})\n",
    "\n",
    "point_to_classify = np.array([9.2,10,12.4]) #will always have same number of items as data_points has columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your answer\n",
    "def knn(point_to_classify, data_points, k):\n",
    "\n",
    "    rows = data_points.shape[0]\n",
    "    features = data_points.shape[1]-1\n",
    "    distances = {}\n",
    "\n",
    "    for row in range(0,rows):\n",
    "        distances[row] = np.sqrt(np.sum((data_points.iloc[row,0:features] - point_to_classify)**2))\n",
    "\n",
    "    nearest = sorted(distances, key=distances.get, reverse=True)[:k]\n",
    "    nearest_classes = list(data_points.iloc[nearest][\"Class\"])\n",
    "    most = max(set(nearest_classes), key = nearest_classes.count)\n",
    "    return(most)\n",
    "\n",
    "knn(point_to_classify, data_points, 10) == \"B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hierarchical\n",
    "\n",
    "In Hierarchical Agglomeretive Clustering, we progressively merge clusters together by determining which two clusters are the closest/most similar. We learned about a few different types of *linkage criteria*. Write three functions: `single(cluster1, cluster2)`, `complete(cluster1, cluster2)`, and `average(cluster1, cluster2)` that compute and return the distance between two clusters using single, complete, and average linkage respectively. Assume you're using euclidean distance for all 3 functions.\n",
    "\n",
    "See below for an example of what `cluster1` and `cluster2` will look like (each row is a data point. but assume they can have any number of data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = pd.DataFrame({\"X\": [6.3,2.9,1.1,2.3,1.9],\n",
    "                        \"Y\": [4.2,-0.9,-2.6,1.5,-1]})\n",
    "cluster2 = pd.DataFrame({\"X\": [-1.2,-2.8,1.4,-2,-1.9],\n",
    "                        \"Y\": [-1.5,1.9,0.9,-0.3,1.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0816653826391966"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single(cluster1,cluster2):\n",
    "    distances = np.ones((cluster1.shape[0],cluster1.shape[0]))\n",
    "\n",
    "    for point in range(0,cluster1.shape[0]):\n",
    "        for point2 in range(0,cluster1.shape[0]):\n",
    "            distances[point,point2] = np.sqrt(np.sum((cluster1.iloc[point,] - cluster2.iloc[point2,])**2))\n",
    "    least = np.amin(distances)\n",
    "    return(least)\n",
    "\n",
    "def complete(cluster1,cluster2):\n",
    "    distances = np.ones((cluster1.shape[0],cluster1.shape[0]))\n",
    "\n",
    "    for point in range(0,cluster1.shape[0]):\n",
    "        for point2 in range(0,cluster1.shape[0]):\n",
    "            distances[point,point2] = np.sqrt(np.sum((cluster1.iloc[point,] - cluster2.iloc[point2,])**2))\n",
    "    most = np.amax(distances)\n",
    "    return(most)\n",
    "\n",
    "def average(cluster1,cluster2):\n",
    "    distances = np.ones((cluster1.shape[0],cluster1.shape[0]))\n",
    "\n",
    "    for point in range(0,cluster1.shape[0]):\n",
    "        for point2 in range(0,cluster1.shape[0]):\n",
    "            distances[point,point2] = np.sqrt(np.sum((cluster1.iloc[point,] - cluster2.iloc[point2,])**2))\n",
    "    av = np.sum(distances)/(cluster1.shape[0]*cluster2.shape[0])\n",
    "    return(av)\n",
    "    \n",
    "\n",
    "\n",
    "single(cluster1, cluster2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.441398201537737"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(cluster1, cluster2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.027741968109063"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average(cluster1, cluster2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
