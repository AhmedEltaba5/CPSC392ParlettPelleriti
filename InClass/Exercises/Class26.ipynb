{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I'm just gonna leave these here...###\n",
    "\n",
    "# get the keys of the three highest values in a dict\n",
    "my_dict = {\"A\":3,\"B\":4,\"H\":1,\"K\":8,\"T\":0}\n",
    "sorted(my_dict, key=my_dict.get, reverse=True)[:3]\n",
    "\n",
    "# square root\n",
    "np.sqrt(9)\n",
    "\n",
    "# adding together elements of a np array...\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,2,3,6])\n",
    "\n",
    "a + b\n",
    "\n",
    "#finding out which item occurs most frequently in a list\n",
    "test_list = [1,1,1,1,3,4,5,6,6,6,7,8,8,8,8,8,8]\n",
    "res = max(set(test_list), key = test_list.count) \n",
    "\n",
    "\n",
    "# if you have a matrix (aka, numpy array) of distances called `distances`, you can find the min value using this code\n",
    "distances = np.array([[9.42019108, 9.38616002, 5.9076222,  9.4413982,  8.63307593],\n",
    " [4.14366987, 6.35059052, 2.3430749,  4.93659802, 5.36656315],\n",
    " [2.54950976, 5.95482997, 3.51283361, 3.86005181, 5.08035432],\n",
    " [4.60977223, 5.11566222, 1.08166538, 4.66154481, 4.2       ],\n",
    " [3.14006369, 5.52268051, 1.96468827, 3.96232255, 4.54862617]])\n",
    "location = np.where(distances == np.amin(distances))\n",
    "print(location)\n",
    "distances[3][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUIZ: Choose 2 of these to complete and turn in in lieu of the last quiz!\n",
    "\n",
    "You may only use numpy and pandas for these (like np.sqrt(), pd.DataFrame()...etc). You should NOT be using built in functions (like sklearn's KNN, or pre-built distance functions) to create the functions. The purpose of this \"quiz\" is for you to get a deeper understanding for these portions of the algorithm's we've learned.\n",
    "\n",
    "Feel free to look up code documentation, but do NOT copy your code from the internet. Make sure to keep a list of all the sources you use for this and put it in your README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. K-Means\n",
    "\n",
    "Once you've chosen random cluster centers to begin with, K-means has two main steps:\n",
    "\n",
    "1. calculate which center each data point is closest to.\n",
    "2. use those cluster assignments to recalculate the center of each cluster.\n",
    "\n",
    "Write two functions: `howFar(centers, points)`, and `calculateCenters(points, assignments)` which do 1 and 2 respectively. See below for an example of what `centers`, `points` and `assignments` will look like. (assume data points have 2 features, and that you're using euclidean distance, but assume that centers and points could be of variable lengths). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame([(10,15), (2,3), (7,7)], columns = [\"X\", \"Y\"])\n",
    "points = pd.DataFrame([(9.09,6.93),(10.79,8.76),(9.07,2.25),\n",
    "                        (7.91,12.59),(3.22,5.61),(5.04,14.04),(13.14,1.22),(3.77,1.54)], columns = [\"X\", \"Y\"])\n",
    "\n",
    "# assignments = [2, 2, 2, 0, 1, 0, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your answer\n",
    "howFar(centers,points) == [2, 2, 2, 0, 1, 0, 2, 1]\n",
    "calculateCenters(points,assignments) == pd.DataFrame([(6.475, 13.315), (3.495, 3.575), (10.5225, 4.789999999999999)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN\n",
    "\n",
    "KNN calculates the distance between each data point and every other data point and finds the k nearest data points. Write a function `knn(point_to_classify, data_points, k)` that predicts/returns the class of `point_to_classify` based on `data_points` and `k`. \n",
    "\n",
    "See below for an example of what `point_to_classify` and `data_points` (each row is a data point) will look like. (Expect that `points_to_classify` could have a variable amount of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = pd.DataFrame({\"X\": [8.9,9,8.7,9.5,10.7,11.8,8.8,10.4,10,10.2,10,10.9,11.4,\n",
    "                                  9,10.3,9.7,10.4,11.3,8.6,10.2,10.9,10.9,10,8.1,10],\n",
    "                           \"Y\": [8.5,9.3,11.3,9.3,11.1,10.1,11.3,9.5,10.6,9.2,8.2,10.6,\n",
    "                                 8.4,9.8,9.4,12.2,9.4,11.7,8.5,11.4,9.9,11.6,8.8,11.9,12],\n",
    "                           \"Z\": [16.8,15.5,15,13.6,15.4,13.8,15.2,13.8,13.7,13.4,12.7,\n",
    "                                 14.4,13.9,15.1,16.2,15.4,14.5,14.6,12.6,14.6,14.1,15.7,\n",
    "                                 13.1,12.3,14.8],\n",
    "                           \"Class\": ['A','A','B','B','B','A','B','A','B','A','A','B','B',\n",
    "                                     'B','B','A','A','B','B','B','A','B','B','B','B']})\n",
    "\n",
    "point_to_classify = [9.2,10,12.4] #will always have same number of items as data_points has columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your answer\n",
    "knn(point_to_classify, data_points, 10) == \"B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hierarchical\n",
    "\n",
    "In Hierarchical Agglomeretive Clustering, we progressively merge clusters together by determining which two clusters are the closest/most similar. We learned about a few different types of *linkage criteria*. Write three functions: `single(cluster1, cluster2)`, `complete(cluster1, cluster2)`, and `average(cluster1, cluster2)` that compute and return the distance between two clusters using single, complete, and average linkage respectively. Assume you're using euclidean distance for all 3 functions.\n",
    "\n",
    "- Single Linkage: smallest distance between two points (one from cluster1, one from cluster2)\n",
    "- Complete Linkage: largest distance between two points (one from cluster1, one from cluster2)\n",
    "- Average Linkage: average distance between all pairs of two points (one from cluster1, one from cluster2)\n",
    "\n",
    "See below for an example of what `cluster1` and `cluster2` will look like (each row is a data point. but assume they can have any number of data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = pd.DataFrame({\"X\": [6.3,2.9,1.1,2.3,1.9],\n",
    "                        \"Y\": [4.2,-0.9,-2.6,1.5,-1]})\n",
    "cluster2 = pd.DataFrame({\"X\": [-1.2,-2.8,1.4,-2,-1.9],\n",
    "                        \"Y\": [-1.5,1.9,0.9,-0.3,1.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your answer\n",
    "\n",
    "single(cluster1, cluster2) == 1.0816653826391966\n",
    "complete(cluster1, cluster2) == 9.441398201537737\n",
    "average(cluster1, cluster2) == 5.027741968109063"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
