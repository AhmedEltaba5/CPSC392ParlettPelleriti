{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Model\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "from sklearn.model_selection import KFold # k-fold cv\n",
    "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
    "from sklearn.model_selection import cross_val_score # cross validation metrics\n",
    "from sklearn.model_selection import cross_val_predict # cross validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework\n",
    "1. Model\n",
    "2. Fit\n",
    "3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>months_subbed</th>\n",
       "      <th>upgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>55.89</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>86.03</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>49.22</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>92.71</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>94.06</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  months_subbed  upgrade\n",
       "0   22   55.89             14        0\n",
       "1   32   86.03             57        0\n",
       "2   38   49.22             37        1\n",
       "3   14   92.71             51        1\n",
       "4   33   94.06             37        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "fashionBIG = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/SKP_fashionBIG.csv\")\n",
    "fashionBIG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"age\", \"income\", \"months_subbed\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fashionBIG[predictors], fashionBIG[\"upgrade\"], test_size = 0.2)\n",
    "\n",
    "zscore = StandardScaler()\n",
    "zscore.fit(X_train)\n",
    "Xz_train = zscore.transform(X_train)\n",
    "Xz_test = zscore.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create\n",
    "myLogit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #fit\n",
    "myLogit.fit(Xz_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #predict\n",
    "y_pred = myLogit.predict(Xz_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23,  56],\n",
       "       [ 18, 103]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionNEW = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/SKP_fashionNEW.csv\")\n",
    "\n",
    "Xnew = fashionNEW[predictors]\n",
    "Xnewz = zscore.transform(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prednew = myLogit.predict(Xnewz)\n",
    "y_prednew[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fashionNEW[\"upgrade\"],y_prednew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88, 309],\n",
       "       [ 98, 505]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(fashionNEW[\"upgrade\"],y_prednew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR different thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36783694, 0.63216306],\n",
       "       [0.49695985, 0.50304015],\n",
       "       [0.46718898, 0.53281102],\n",
       "       [0.40031463, 0.59968537],\n",
       "       [0.44647647, 0.55352353],\n",
       "       [0.48817161, 0.51182839],\n",
       "       [0.43368209, 0.56631791],\n",
       "       [0.36554565, 0.63445435],\n",
       "       [0.55823765, 0.44176235]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = myLogit.predict_proba(Xnewz)\n",
    "y_pred_prob[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46451303, 0.63216306, 0.50304015, 0.53281102, 0.59968537,\n",
       "       0.55352353, 0.51182839, 0.56631791, 0.63445435, 0.44176235,\n",
       "       0.58714254, 0.58296231, 0.38065364, 0.52407398, 0.50634059,\n",
       "       0.50361224, 0.40389766, 0.55943233, 0.71635563, 0.60150194,\n",
       "       0.53426069, 0.57146995, 0.61125067, 0.59609572, 0.42571684,\n",
       "       0.64305188, 0.57010735, 0.54201657, 0.6040882 , 0.53666118,\n",
       "       0.53317216, 0.49043288, 0.46259887, 0.56908189, 0.46925144,\n",
       "       0.40270868, 0.7202828 , 0.65318475, 0.58376237, 0.39431859,\n",
       "       0.54750163, 0.68157393, 0.55807904, 0.71876599, 0.53096995,\n",
       "       0.59360079, 0.57389025, 0.66094908, 0.62197431, 0.57444225,\n",
       "       0.54296361, 0.60335541, 0.64634083, 0.63151076, 0.59315245,\n",
       "       0.46422049, 0.54489489, 0.66925014, 0.61163021, 0.5424711 ,\n",
       "       0.57760224, 0.67805627, 0.56122529, 0.62302153, 0.51819961,\n",
       "       0.59610335, 0.65468447, 0.62898262, 0.71735318, 0.59389539,\n",
       "       0.51417775, 0.67420983, 0.37787342, 0.46649462, 0.44950668,\n",
       "       0.69717178, 0.6702571 , 0.59797361, 0.59410745, 0.54968897,\n",
       "       0.63626625, 0.41756023, 0.51638767, 0.42561656, 0.5800315 ,\n",
       "       0.50037956, 0.63375486, 0.60160099, 0.56852981, 0.6865118 ,\n",
       "       0.46880601, 0.60355526, 0.60807374, 0.72245726, 0.69571912,\n",
       "       0.57100909, 0.67600444, 0.57439501, 0.55152079, 0.66300846,\n",
       "       0.55421754, 0.67653295, 0.53108412, 0.48784447, 0.58048074,\n",
       "       0.55879219, 0.49993421, 0.3852212 , 0.57865031, 0.61218086,\n",
       "       0.59629743, 0.46020013, 0.57895508, 0.5821809 , 0.60446306,\n",
       "       0.54149505, 0.42734925, 0.53185129, 0.63706022, 0.59667621,\n",
       "       0.5521016 , 0.5510832 , 0.60704958, 0.65801362, 0.52496169,\n",
       "       0.67717453, 0.4675209 , 0.64458733, 0.59161598, 0.72582206,\n",
       "       0.62188105, 0.59950399, 0.54015721, 0.59357037, 0.50895295,\n",
       "       0.67430342, 0.67888207, 0.575799  , 0.59534082, 0.65316597,\n",
       "       0.57332953, 0.63539552, 0.42693542, 0.75396431, 0.49217484,\n",
       "       0.62126072, 0.52137004, 0.57470735, 0.65895686, 0.50019624,\n",
       "       0.51524715, 0.48682612, 0.58827781, 0.49273591, 0.48943926,\n",
       "       0.63779368, 0.62457381, 0.67351669, 0.56310739, 0.64736803,\n",
       "       0.64309655, 0.66306419, 0.59079908, 0.42670144, 0.5887206 ,\n",
       "       0.59530095, 0.49539977, 0.66821105, 0.65928107, 0.57636784,\n",
       "       0.57120765, 0.62245329, 0.53319492, 0.57364859, 0.5201048 ,\n",
       "       0.63797198, 0.5652956 , 0.56049403, 0.63392749, 0.56670508,\n",
       "       0.59516173, 0.48672859, 0.37313665, 0.52416866, 0.509504  ,\n",
       "       0.4287411 , 0.57689854, 0.58023853, 0.61459341, 0.4353114 ,\n",
       "       0.63307554, 0.54240413, 0.56306138, 0.45567853, 0.71009935,\n",
       "       0.50998382, 0.60407149, 0.57815797, 0.6453608 , 0.59095882,\n",
       "       0.48897492, 0.44841999, 0.49763018, 0.53650889, 0.56014543,\n",
       "       0.59395003, 0.51209776, 0.59835524, 0.61046062, 0.64008293,\n",
       "       0.63069665, 0.58451906, 0.555747  , 0.48364293, 0.43679472,\n",
       "       0.52427926, 0.56064112, 0.56519266, 0.65164089, 0.63450909,\n",
       "       0.67934085, 0.61520924, 0.54694163, 0.51061045, 0.59450247,\n",
       "       0.55512644, 0.59059901, 0.6134584 , 0.56861011, 0.57197187,\n",
       "       0.5471116 , 0.5634145 , 0.67457726, 0.54274821, 0.45295014,\n",
       "       0.55061953, 0.49062701, 0.53412566, 0.48564203, 0.59130697,\n",
       "       0.70534679, 0.45167338, 0.58361173, 0.57319483, 0.51769002,\n",
       "       0.52438121, 0.39801823, 0.6164028 , 0.62465931, 0.63324142,\n",
       "       0.52337   , 0.49586831, 0.64633231, 0.68985947, 0.47117461,\n",
       "       0.55073401, 0.48773963, 0.64763267, 0.39331801, 0.49885226,\n",
       "       0.61186729, 0.35670191, 0.60050262, 0.60679041, 0.57455082,\n",
       "       0.55464592, 0.66601798, 0.66226992, 0.55030761, 0.50123898,\n",
       "       0.55905966, 0.56795084, 0.48438842, 0.47461658, 0.60695299,\n",
       "       0.45118559, 0.626563  , 0.67208671, 0.6073255 , 0.52138176,\n",
       "       0.40070979, 0.5392516 , 0.63651315, 0.63541348, 0.62144004,\n",
       "       0.61140824, 0.67229525, 0.5571668 , 0.61668294, 0.56748535,\n",
       "       0.60806608, 0.61044006, 0.38783431, 0.56204365, 0.50751081,\n",
       "       0.434167  , 0.57306707, 0.57822524, 0.43065611, 0.42047282,\n",
       "       0.50882577, 0.67710561, 0.54922459, 0.49056652, 0.62478414,\n",
       "       0.55187213, 0.45659876, 0.51456749, 0.67555342, 0.58598153,\n",
       "       0.44894587, 0.35158072, 0.54563589, 0.67797705, 0.5102041 ,\n",
       "       0.62223842, 0.53996518, 0.45608481, 0.56912267, 0.68547023,\n",
       "       0.53684082, 0.5674514 , 0.52928391, 0.57218969, 0.49068894,\n",
       "       0.62229364, 0.63462407, 0.74048597, 0.67097951, 0.5047444 ,\n",
       "       0.50145707, 0.52197656, 0.55917151, 0.50364653, 0.52256574,\n",
       "       0.47038754, 0.46370759, 0.55974585, 0.64040211, 0.50348007,\n",
       "       0.55983307, 0.58886469, 0.5719414 , 0.55788787, 0.62261737,\n",
       "       0.66724938, 0.59178638, 0.52598279, 0.57367988, 0.55269703,\n",
       "       0.60335017, 0.61715521, 0.69402225, 0.5993409 , 0.39467376,\n",
       "       0.71837136, 0.59808793, 0.61337415, 0.63069975, 0.54825266,\n",
       "       0.58199788, 0.64872265, 0.55333609, 0.72695385, 0.56108056,\n",
       "       0.54557375, 0.56995818, 0.56880781, 0.57807905, 0.55887368,\n",
       "       0.62499174, 0.59339282, 0.53745606, 0.6503486 , 0.47943303,\n",
       "       0.57965057, 0.46557254, 0.67419848, 0.6787271 , 0.5530477 ,\n",
       "       0.63655055, 0.51113272, 0.36707759, 0.54067266, 0.71693134,\n",
       "       0.59491946, 0.32182925, 0.60024169, 0.45661944, 0.51130377,\n",
       "       0.51696076, 0.61205358, 0.5713149 , 0.47198867, 0.62542783,\n",
       "       0.63298364, 0.56308168, 0.57992029, 0.67594982, 0.62642005,\n",
       "       0.67081299, 0.38802592, 0.73105734, 0.58469991, 0.44370957,\n",
       "       0.47864512, 0.54140589, 0.54750557, 0.58627721, 0.4446534 ,\n",
       "       0.5206012 , 0.59568411, 0.52755144, 0.54231614, 0.77718596,\n",
       "       0.46817247, 0.61584778, 0.6328127 , 0.48722521, 0.46554005,\n",
       "       0.50211804, 0.52209121, 0.5680807 , 0.69137403, 0.52749843,\n",
       "       0.54897159, 0.6235384 , 0.59170333, 0.52101053, 0.60394447,\n",
       "       0.51920453, 0.53762816, 0.47659463, 0.54858012, 0.62751176,\n",
       "       0.66669163, 0.60204434, 0.64691905, 0.66965549, 0.66241039,\n",
       "       0.47343216, 0.59248954, 0.51682076, 0.49268931, 0.45836305,\n",
       "       0.37202365, 0.41378655, 0.61815308, 0.64675757, 0.64042999,\n",
       "       0.72481123, 0.57823027, 0.65421406, 0.63335953, 0.59288688,\n",
       "       0.65863821, 0.61235207, 0.59681145, 0.56806668, 0.55092392,\n",
       "       0.56009301, 0.58902394, 0.59144643, 0.53138229, 0.47302445,\n",
       "       0.52336397, 0.54055342, 0.44637368, 0.51239791, 0.59974768,\n",
       "       0.61354069, 0.49780842, 0.58062684, 0.44974057, 0.64147425,\n",
       "       0.67660879, 0.68605404, 0.60580126, 0.54642471, 0.57564852,\n",
       "       0.46525947, 0.58928061, 0.628091  , 0.50832002, 0.60433005,\n",
       "       0.54610998, 0.62201113, 0.63331991, 0.67074131, 0.69332975,\n",
       "       0.54471553, 0.50810095, 0.52666286, 0.54026313, 0.50082226,\n",
       "       0.5368542 , 0.58884934, 0.68679226, 0.72671387, 0.48393487,\n",
       "       0.70072129, 0.60785311, 0.55236423, 0.63906477, 0.61426614,\n",
       "       0.70061289, 0.63624955, 0.56773909, 0.51223539, 0.47009044,\n",
       "       0.44677401, 0.50535717, 0.52784933, 0.5478687 , 0.42299903,\n",
       "       0.56818667, 0.70159286, 0.69629171, 0.5092703 , 0.70120756,\n",
       "       0.39731433, 0.50468093, 0.52554622, 0.59086987, 0.60658849,\n",
       "       0.67278625, 0.5420087 , 0.5337482 , 0.51536798, 0.5577325 ,\n",
       "       0.61574141, 0.57294725, 0.54358873, 0.47100022, 0.6231611 ,\n",
       "       0.46435353, 0.6208824 , 0.65988003, 0.63731   , 0.52479493,\n",
       "       0.5342763 , 0.48727981, 0.53992354, 0.56504607, 0.54438617,\n",
       "       0.56368973, 0.54855118, 0.48362088, 0.53889905, 0.53462161,\n",
       "       0.63445481, 0.56696108, 0.46422913, 0.63704915, 0.57236786,\n",
       "       0.6094298 , 0.46690325, 0.56461979, 0.48900771, 0.57412098,\n",
       "       0.74612537, 0.47512869, 0.49120878, 0.55773241, 0.57695973,\n",
       "       0.67969405, 0.64345947, 0.51751607, 0.55985989, 0.5479395 ,\n",
       "       0.51804445, 0.46293945, 0.57690782, 0.57802059, 0.49125399,\n",
       "       0.53737097, 0.62350101, 0.50725084, 0.59595511, 0.65918701,\n",
       "       0.55014114, 0.71327826, 0.66548666, 0.37416818, 0.55624847,\n",
       "       0.68354257, 0.60084034, 0.53522948, 0.50513969, 0.63933454,\n",
       "       0.39294414, 0.64428598, 0.58887276, 0.5066917 , 0.63428031,\n",
       "       0.54397896, 0.51581425, 0.60046345, 0.62770808, 0.57664214,\n",
       "       0.38348306, 0.5926471 , 0.37945347, 0.7195641 , 0.59002194,\n",
       "       0.61745053, 0.59401611, 0.52095385, 0.69059109, 0.59203982,\n",
       "       0.59021146, 0.51319495, 0.61422747, 0.56631983, 0.47677454,\n",
       "       0.53881167, 0.6010733 , 0.62408784, 0.6388437 , 0.44064911,\n",
       "       0.43155851, 0.57355489, 0.58715115, 0.52901974, 0.49813111,\n",
       "       0.64563936, 0.51884606, 0.51424749, 0.51581356, 0.57729209,\n",
       "       0.52977951, 0.54787268, 0.74049206, 0.59091495, 0.49358266,\n",
       "       0.70658193, 0.67668043, 0.56314625, 0.50737125, 0.4595954 ,\n",
       "       0.47524055, 0.59063113, 0.467787  , 0.63383346, 0.38270198,\n",
       "       0.66633315, 0.5468232 , 0.59954191, 0.56501558, 0.60389568,\n",
       "       0.76748591, 0.55241205, 0.65385014, 0.51586034, 0.5169216 ,\n",
       "       0.64721313, 0.53960853, 0.42856825, 0.44377611, 0.47543137,\n",
       "       0.51221475, 0.40537145, 0.34982215, 0.6399808 , 0.61321251,\n",
       "       0.63759651, 0.65166035, 0.62553594, 0.69288238, 0.4748404 ,\n",
       "       0.61911582, 0.62554599, 0.48007923, 0.55949718, 0.66368771,\n",
       "       0.45717813, 0.5147918 , 0.51781809, 0.4477605 , 0.43888165,\n",
       "       0.60850779, 0.63346613, 0.58345355, 0.64124388, 0.57571766,\n",
       "       0.65486848, 0.60109171, 0.56673087, 0.3945386 , 0.60196392,\n",
       "       0.61369032, 0.58720659, 0.53420593, 0.59906249, 0.53067867,\n",
       "       0.46985674, 0.55085748, 0.56509879, 0.6528554 , 0.58837021,\n",
       "       0.55096952, 0.62650165, 0.56064558, 0.72802537, 0.59496361,\n",
       "       0.38699717, 0.67899597, 0.44030459, 0.55196502, 0.57670728,\n",
       "       0.59520638, 0.43006599, 0.52680772, 0.53979221, 0.64052514,\n",
       "       0.61762232, 0.60472118, 0.62028443, 0.50635208, 0.51358404,\n",
       "       0.5279344 , 0.58621894, 0.56975729, 0.71584508, 0.50135523,\n",
       "       0.41891293, 0.59483401, 0.64954766, 0.51954832, 0.73808805,\n",
       "       0.65497931, 0.62336151, 0.66711778, 0.61432159, 0.49000312,\n",
       "       0.46984514, 0.62286509, 0.50227838, 0.73630753, 0.44481174,\n",
       "       0.50115737, 0.62667534, 0.44980792, 0.57004211, 0.52782731,\n",
       "       0.62406834, 0.46441238, 0.64169342, 0.59250586, 0.60689728,\n",
       "       0.70184475, 0.57955385, 0.51026573, 0.53911272, 0.72371395,\n",
       "       0.70677129, 0.54330502, 0.72655663, 0.55907044, 0.6314265 ,\n",
       "       0.65455248, 0.5860961 , 0.50267538, 0.64797596, 0.64755747,\n",
       "       0.60425121, 0.6746772 , 0.53399141, 0.50182681, 0.53010465,\n",
       "       0.63531964, 0.61701529, 0.59691111, 0.5399864 , 0.57522078,\n",
       "       0.56881028, 0.53767845, 0.62769733, 0.4475389 , 0.67138093,\n",
       "       0.54648109, 0.65251768, 0.61116332, 0.39610133, 0.45860137,\n",
       "       0.64343967, 0.60440239, 0.56855192, 0.57927574, 0.45637015,\n",
       "       0.51176623, 0.587058  , 0.5551789 , 0.68055175, 0.67465712,\n",
       "       0.63715016, 0.57726174, 0.50153153, 0.46868763, 0.6386292 ,\n",
       "       0.52049401, 0.61411718, 0.66238966, 0.4056285 , 0.51887713,\n",
       "       0.57001569, 0.55606747, 0.64569855, 0.49082979, 0.54082942,\n",
       "       0.62237346, 0.57573322, 0.62286799, 0.42788845, 0.44891085,\n",
       "       0.42319358, 0.573856  , 0.50431775, 0.50487268, 0.63421129,\n",
       "       0.67508355, 0.57544698, 0.63523521, 0.44997428, 0.45938109,\n",
       "       0.50070947, 0.55427102, 0.48966049, 0.63174382, 0.62974558,\n",
       "       0.50665972, 0.60807244, 0.51221266, 0.61118488, 0.59654371,\n",
       "       0.64186969, 0.49505637, 0.46985112, 0.69950584, 0.5946711 ,\n",
       "       0.59589466, 0.50445754, 0.48115542, 0.59602383, 0.64624723,\n",
       "       0.58783718, 0.57452301, 0.6697982 , 0.5579723 , 0.46744082,\n",
       "       0.58259967, 0.59091797, 0.60791517, 0.66951258, 0.45717428,\n",
       "       0.5337973 , 0.57439056, 0.59413498, 0.58640622, 0.58403109,\n",
       "       0.62951853, 0.61059694, 0.56994258, 0.55519748, 0.52845531,\n",
       "       0.59253863, 0.53840015, 0.54175965, 0.50677681, 0.56726395,\n",
       "       0.71716613, 0.48127335, 0.64446372, 0.59466978, 0.69964741,\n",
       "       0.58493135, 0.3900436 , 0.52469624, 0.59951734, 0.5263133 ,\n",
       "       0.32528306, 0.48883255, 0.50825043, 0.42866104, 0.74923754,\n",
       "       0.75582811, 0.66217551, 0.47894005, 0.6549    , 0.6154148 ,\n",
       "       0.70057094, 0.65539856, 0.47503381, 0.54770855, 0.4688883 ,\n",
       "       0.61921881, 0.79678084, 0.48831685, 0.59204074, 0.5772601 ,\n",
       "       0.52871464, 0.5208974 , 0.66563098, 0.51788323, 0.57684001,\n",
       "       0.55075198, 0.62468658, 0.54888165, 0.64252471, 0.55082619,\n",
       "       0.63505732, 0.54669159, 0.54987441, 0.62427657, 0.66325959,\n",
       "       0.5513426 , 0.61643188, 0.59131572, 0.56423664, 0.58855422,\n",
       "       0.59402863, 0.72607796, 0.57941014, 0.72263594, 0.510659  ,\n",
       "       0.63931949, 0.38683351, 0.57233101, 0.65032885, 0.46862776,\n",
       "       0.60628769, 0.60397   , 0.67161633, 0.65035922, 0.56250949,\n",
       "       0.51945341, 0.69835328, 0.51455467, 0.47484059, 0.54810825,\n",
       "       0.55081442, 0.66870008, 0.62603583, 0.47822195, 0.62820268,\n",
       "       0.62681622, 0.62496226, 0.5497779 , 0.51478118, 0.46345283,\n",
       "       0.59143571, 0.54350925, 0.47935859, 0.66341533, 0.62820718,\n",
       "       0.52958754, 0.60371592, 0.48324747, 0.45657713, 0.57413566,\n",
       "       0.67883565, 0.65463082, 0.48062354, 0.43993873, 0.56823049,\n",
       "       0.54735246, 0.57983848, 0.64317247, 0.54912004, 0.53901746,\n",
       "       0.49691379, 0.51337722, 0.63708497, 0.67250114, 0.66376881,\n",
       "       0.58599319, 0.46705099, 0.47428388, 0.50769275, 0.45696175,\n",
       "       0.5324766 , 0.51699939, 0.55219242, 0.54902976, 0.56377162,\n",
       "       0.60844908, 0.68661253, 0.58775664, 0.65520503, 0.52943675,\n",
       "       0.67098265, 0.5609582 , 0.55853681, 0.66651826, 0.4293486 ,\n",
       "       0.62719907, 0.51323235, 0.46762205, 0.6935661 , 0.45681032])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob1 = y_pred_prob[:,1]\n",
    "y_pred_prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.7\n",
    "\n",
    "y_pred_prob1_thresh = (y_pred_prob1 >= thresh)*1\n",
    "y_pred_prob1_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold\n",
    "X = fashionBIG[[\"age\", \"income\", \"months_subbed\"]]\n",
    "y = fashionBIG[\"upgrade\"]\n",
    "\n",
    "\n",
    "# create k-fold object\n",
    "kf = KFold(n_splits = 5)\n",
    "kf.split(X)\n",
    "\n",
    "lr = LogisticRegression() #create model\n",
    "\n",
    "acc = [] #create empty list to store accuracy for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58, 0.605, 0.54, 0.565, 0.645]\n",
      "0.587\n"
     ]
    }
   ],
   "source": [
    "# Use a for loop to loop through each fold and train a model, then add the accuracy to acc.\n",
    "\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    # Get your train/test for this fold\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    \n",
    "    # standardize\n",
    "    \n",
    "    zscore = StandardScaler()\n",
    "    zscore.fit(X_train)\n",
    "    Xz_train = zscore.transform(X_train)\n",
    "    Xz_test = zscore.transform(X_test)\n",
    "    \n",
    "    # model\n",
    "    model = lr.fit(Xz_train, y_train)\n",
    "    \n",
    "    acc.append(accuracy_score(y_test, model.predict(Xz_test)))\n",
    "\n",
    "    # record accuracy\n",
    "\n",
    "    \n",
    "#print overall acc\n",
    "print(acc)\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"age\", \"income\", \"months_subbed\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fashionBIG[predictors], fashionBIG[\"upgrade\"], test_size = 0.2)\n",
    "\n",
    "zscore = StandardScaler()\n",
    "zscore.fit(X_train)\n",
    "Xz_train = zscore.transform(X_train)\n",
    "Xz_test = zscore.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3715105  0.00347919 0.06299273]]\n",
      "[0.28630292]\n"
     ]
    }
   ],
   "source": [
    "# Default Regularization\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# myLogit = LogisticRegression()\n",
    "\n",
    "#create\n",
    "myLogit = LogisticRegression(penalty = \"none\") #create\n",
    "#fit\n",
    "myLogit.fit(Xz_train,y_train)\n",
    "\n",
    "print(myLogit.coef_)\n",
    "print(myLogit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xz_train2 = sm.add_constant(Xz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.667155\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>upgrade</td>     <th>  No. Observations:  </th>  <td>   800</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   796</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 09 Mar 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.02415</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:58:42</td>     <th>  Log-Likelihood:    </th> <td> -533.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -546.93</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>7.808e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2863</td> <td>    0.073</td> <td>    3.940</td> <td> 0.000</td> <td>    0.144</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.3715</td> <td>    0.075</td> <td>    4.938</td> <td> 0.000</td> <td>    0.224</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0035</td> <td>    0.073</td> <td>    0.048</td> <td> 0.962</td> <td>   -0.139</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0630</td> <td>    0.073</td> <td>    0.867</td> <td> 0.386</td> <td>   -0.079</td> <td>    0.205</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                upgrade   No. Observations:                  800\n",
       "Model:                          Logit   Df Residuals:                      796\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 09 Mar 2020   Pseudo R-squ.:                 0.02415\n",
       "Time:                        16:58:42   Log-Likelihood:                -533.72\n",
       "converged:                       True   LL-Null:                       -546.93\n",
       "Covariance Type:            nonrobust   LLR p-value:                 7.808e-06\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2863      0.073      3.940      0.000       0.144       0.429\n",
       "x1             0.3715      0.075      4.938      0.000       0.224       0.519\n",
       "x2             0.0035      0.073      0.048      0.962      -0.139       0.146\n",
       "x3             0.0630      0.073      0.867      0.386      -0.079       0.205\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(y_train, Xz_train2)\n",
    "output = model.fit()\n",
    "output.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
